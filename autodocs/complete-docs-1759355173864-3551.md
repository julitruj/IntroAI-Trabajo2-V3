# DocumentaciÃ³n del Proyecto

## GuÃ­a de Usuario
# GuÃ­a de Usuario

Bienvenido a nuestra herramienta de anÃ¡lisis y procesamiento de informaciÃ³n, diseÃ±ada para ayudarte a extraer valor de documentos PDF, conversaciones y datos de voz de clientes mediante una interfaz web interactiva y el poder de la inteligencia artificial.

## ğŸ“± Â¿QuÃ© es esta aplicaciÃ³n?

- **PropÃ³sito principal**:  
  Esta aplicaciÃ³n estÃ¡ diseÃ±ada para simplificar el anÃ¡lisis de documentos PDF y conversaciones, integrando modelos de lenguaje basados en inteligencia artificial para ofrecer insights Ãºtiles sobre el contenido y la Voz del Cliente (VoC).

- **Problema que resuelve**:  
  Te ayuda a procesar grandes volÃºmenes de informaciÃ³n de manera rÃ¡pida y precisa, eliminando la necesidad de revisar manualmente documentos largos y conversaciones, lo que permite tomar decisiones informadas y oportunas.

- **Beneficios clave**:  
  â€¢ Ahorro de tiempo en la extracciÃ³n de datos esenciales.  
  â€¢ AnÃ¡lisis automatizado y detallado de documentos y conversaciones.  
  â€¢ Acceso a insights precisos sobre la experiencia del cliente.  
  â€¢ Interfaz sencilla e intuitiva para usuarios sin conocimientos tÃ©cnicos avanzados.

- **Audiencia objetivo**:  
  Profesionales, analistas y equipos de atenciÃ³n al cliente que necesiten extraer y analizar informaciÃ³n de documentos PDF, conversaciones o llamadas, y que busquen comprender mejor la Voz del Cliente.

## âœ¨ Funcionalidades Principales

### Interfaz Web Interactiva con Streamlit
- **Â¿QuÃ© hace?**:  
  Proporciona una plataforma amigable y visual para interactuar con las demÃ¡s funcionalidades de la aplicaciÃ³n.
  
- **Â¿CuÃ¡ndo usarla?**:  
  Ideal cada vez que necesites cargar documentos, iniciar anÃ¡lisis o visualizar resultados de manera rÃ¡pida y sencilla.
  
- **Â¿CÃ³mo acceder?**:  
  Abre tu navegador y navega a la URL proporcionada para la aplicaciÃ³n. Una vez allÃ­, podrÃ¡s ver el menÃº principal con las opciones disponibles.
  
- **Resultado esperado**:  
  Una experiencia visual clara donde puedes seleccionar y operar las demÃ¡s funcionalidades sin complicaciones.

### Procesamiento de Archivos PDF
- **Â¿QuÃ© hace?**:  
  Permite importar y extraer informaciÃ³n relevante de archivos PDF.
  
- **Â¿CuÃ¡ndo usarla?**:  
  Ãšsala cuando necesites analizar datos de documentos PDF, como reportes, facturas, manuales o cualquier otro tipo de contenido textual.
  
- **Â¿CÃ³mo acceder?**:  
  Desde la interfaz web, selecciona la opciÃ³n â€œProcesar PDFâ€, sube el archivo deseado y espera a que la aplicaciÃ³n extraiga el contenido.
  
- **Resultado esperado**:  
  VisualizaciÃ³n del texto extraÃ­do del PDF, listo para ser analizado o convertido en insights.

### AnÃ¡lisis con Modelos de Lenguaje (IA)
- **Â¿QuÃ© hace?**:  
  Emplea inteligencia artificial para analizar y extraer informaciÃ³n clave del texto procesado.
  
- **Â¿CuÃ¡ndo usarla?**:  
  Cuando necesites interpretar el contenido textual para identificar patrones, sentimientos o insights especÃ­ficos.
  
- **Â¿CÃ³mo acceder?**:  
  Una vez que has procesado un archivo PDF o ingresado texto, selecciona â€œAnalizar con IAâ€ desde el menÃº de opciones.
  
- **Resultado esperado**:  
  Un anÃ¡lisis detallado y resumido del contenido, con insights relevantes y sugerencias de acciÃ³n basadas en el texto.

### AnÃ¡lisis de Conversaciones
- **Â¿QuÃ© hace?**:  
  Permite analizar transcripciones o registros de conversaciones para identificar temas, emociones y puntos clave en la comunicaciÃ³n.
  
- **Â¿CuÃ¡ndo usarla?**:  
  Ideal para equipos de servicio al cliente, marketing o recursos humanos que quieran evaluar interacciones importantes con sus stakeholders.
  
- **Â¿CÃ³mo acceder?**:  
  Selecciona â€œAnalizar Conversacionesâ€ en la interfaz, sube el archivo o copia la transcripciÃ³n y procede con la acciÃ³n de anÃ¡lisis.
  
- **Resultado esperado**:  
  Un reporte que destaca temas recurrentes, anÃ¡lisis de sentimientos y posibles Ã¡reas de mejora en la comunicaciÃ³n.

### AnÃ¡lisis de Voz del Cliente (VoC)
- **Â¿QuÃ© hace?**:  
  EvalÃºa la retroalimentaciÃ³n y expresiones de los clientes extraÃ­das de diferentes fuentes (documentos, conversaciones o registros de voz) para identificar necesidades y Ã¡reas de mejora.
  
- **Â¿CuÃ¡ndo usarla?**:  
  Ãšsala cuando requieras una comprensiÃ³n profunda sobre la experiencia del cliente y identificar oportunidades para mejorar el servicio o producto.
  
- **Â¿CÃ³mo acceder?**:  
  En la interfaz web, selecciona â€œAnÃ¡lisis de Voz del Clienteâ€ y sigue las instrucciones para cargar la fuente de datos deseada.
  
- **Resultado esperado**:  
  Un informe sintetizado con los conceptos clave de la experiencia del cliente, resaltando puntos positivos y Ã¡reas crÃ­ticas.

## ğŸš€ CÃ³mo Empezar

### Primer Uso
1. **Requisitos previos**:  
   AsegÃºrate de contar con un navegador actualizado y conexiÃ³n a internet. Ten a la mano los archivos PDF o transcripciones que desees analizar.

2. **Acceso inicial**:  
   Ingresa a la URL de la aplicaciÃ³n desde tu navegador. La pÃ¡gina principal te darÃ¡ la bienvenida y mostrarÃ¡ las opciones disponibles.

3. **ConfiguraciÃ³n bÃ¡sica**:  
   No se requiere configuraciÃ³n avanzada. Solo debes dirigirte a la secciÃ³n deseada, cargar tu archivo o introducir el texto, y seguir las instrucciones en pantalla.

4. **Primera tarea recomendada**:  
   Empieza probando la funcionalidad de â€œProcesamiento de Archivos PDFâ€, cargando un documento de tu interÃ©s para familiarizarte con la herramienta.

### Flujo TÃ­pico de Uso
1. **Paso 1**:  
   Accede a la interfaz web e identifica la funcionalidad que necesitas (por ejemplo, â€œProcesar PDFâ€ o â€œAnalizar Conversacionesâ€).

2. **Paso 2**:  
   Sube el archivo o ingresa el texto requerido. La aplicaciÃ³n procesarÃ¡ esta informaciÃ³n automÃ¡ticamente.

3. **Paso 3**:  
   Revisa los resultados del anÃ¡lisis: el sistema te mostrarÃ¡ reportes claros y fÃ¡ciles de interpretar con insights relevantes.

## ğŸ’¡ Casos de Uso Comunes

### Escenario 1: AnÃ¡lisis de Reportes Financieros
**SituaciÃ³n**: Necesitas revisar y extraer datos clave de un extenso reporte financiero en PDF.  
**Pasos**: 
1. Sube el PDF en la secciÃ³n â€œProcesar PDFâ€.  
2. Ejecuta el â€œAnÃ¡lisis con IAâ€ para extraer conceptos financieros crÃ­ticos.  
3. Revisa el reporte y enfÃ³cate en las cifras y tendencias mÃ¡s relevantes.

### Escenario 2: EvaluaciÃ³n de Llamadas de AtenciÃ³n al Cliente
**SituaciÃ³n**: Deseas analizar la transcripciÃ³n de las llamadas de soporte para mejorar la atenciÃ³n.  
**Pasos**: 
1. Importa la transcripciÃ³n en â€œAnalizar Conversacionesâ€.  
2. Observa el anÃ¡lisis de sentimientos y temas recurrentes.  
3. Identifica oportunidades de capacitaciÃ³n para el equipo.

### Escenario 3: Monitoreo de la Voz del Cliente
**SituaciÃ³n**: Quieres conocer la percepciÃ³n de tus clientes sobre un nuevo producto.  
**Pasos**: 
1. Recopila comentarios y transcripciones de redes sociales, encuestas o llamadas.  
2. Usa la funcionalidad â€œAnÃ¡lisis de Voz del Clienteâ€ para sintetizar la retroalimentaciÃ³n.  
3. Revisa el informe y adapta estrategias de marketing o mejora de producto.

## â“ Preguntas Frecuentes

P: Â¿CÃ³mo subo un archivo PDF para procesar?  
R: Simplemente dirÃ­gete a la opciÃ³n â€œProcesar PDFâ€, haz clic en el botÃ³n para cargar archivos y selecciona el documento desde tu dispositivo.

P: Â¿QuÃ© hago si el anÃ¡lisis de conversaciÃ³n no muestra resultados claros?  
R: Revisa que la transcripciÃ³n estÃ© completa y en formato de texto. Si el problema persiste, intenta reiniciar la carga del archivo.

P: Â¿Es seguro usar la funcionalidad de anÃ¡lisis con modelos de lenguaje?  
R: SÃ­, la aplicaciÃ³n utiliza algoritmos seguros y probados para analizar el contenido, sin almacenar informaciÃ³n sensible de manera permanente.

P: Â¿CuÃ¡les son las limitaciones principales?  
R: La aplicaciÃ³n actualmente sÃ³lo procesa documentos en formatos PDF y texto, y el anÃ¡lisis se basa en la calidad de la informaciÃ³n ingresada. No puede interpretar contenido multimedia o imÃ¡genes dentro de los PDF.

## ğŸ†˜ SoluciÃ³n de Problemas

### Problema: El archivo PDF no se carga correctamente
**SÃ­ntomas**: El sistema no reconoce el archivo o aparece un mensaje de error.  
**Causa probable**: El archivo podrÃ­a estar daÃ±ado o no ser compatible con el formato requerido.  
**SoluciÃ³n**:  
1. Verifica que el documento estÃ© en formato PDF y que no estÃ© corrupto.  
2. Intenta cargarlo nuevamente o utiliza otro archivo similar.

### Problema: Los resultados del anÃ¡lisis no son precisos
**SÃ­ntomas**: El informe de anÃ¡lisis carece de informaciÃ³n relevante o muestra datos inconsistentes.  
**Causa probable**: El texto de origen podrÃ­a tener errores o estar incompleto.  
**SoluciÃ³n**:  
1. Revisa el contenido del documento o la transcripciÃ³n para verificar su integridad.  
2. Vuelve a ejecutar el proceso de anÃ¡lisis asegurÃ¡ndote de que el texto de origen sea correcto.

### Problema: La aplicaciÃ³n tarda demasiado en responder
**SÃ­ntomas**: La interfaz se congela o responde muy lentamente.  
**Causa probable**: PodrÃ­a haber problemas de conexiÃ³n a internet o sobrecarga en el servidor.  
**SoluciÃ³n**:  
1. Revisa tu conexiÃ³n a internet.  
2. Espera unos minutos y vuelve a intentarlo.  
3. Si el problema persiste, contacta al soporte.

## ğŸ“ Soporte y Contacto
- **Â¿Necesitas ayuda adicional?**  
  Contacta al equipo de soporte a travÃ©s del correo soporte@tuanalisis.com o llama al +34 123 456 789.
  
- **Â¿Encontraste un error?**  
  Reporta cualquier fallo o inconveniente mediante el formulario de feedback disponible en la secciÃ³n â€œContactoâ€ de la aplicaciÃ³n.

- **Â¿Tienes sugerencias?**  
  EnvÃ­anos tus ideas y comentarios a feedback@tuanalisis.com para ayudarnos a mejorar la herramienta.

---

Esperamos que esta guÃ­a te ayude a aprovechar al mÃ¡ximo todas las funcionalidades que nuestra herramienta te ofrece. Â¡Bienvenido a una nueva era de anÃ¡lisis inteligente y eficiente!

## DocumentaciÃ³n TÃ©cnica
A continuaciÃ³n se muestra la documentaciÃ³n tÃ©cnica completa en Markdown, organizada segÃºn la estructura obligatoria solicitada y basada en el anÃ¡lisis del repositorio y las muestras de cÃ³digo proporcionadas.

------------------------------------------------------------
# DocumentaciÃ³n TÃ©cnica

Esta documentaciÃ³n estÃ¡ orientada a desarrolladores y equipos tÃ©cnicos interesados en comprender, mantener y extender la aplicaciÃ³n VoC Analyst. La herramienta permite procesar archivos (por ejemplo, documentos PDF) y analizar la Voz del Cliente (VoC) mediante modelos de lenguaje (LLM). La interfaz se implementa con Streamlit y el procesamiento se realiza en un Ãºnico sistema modular que integra extracciÃ³n de texto, parsing de conversaciones (con redacciÃ³n de PII) y conexiÃ³n con proveedores externos de IA (como OpenAI, Anthropic y Google GenAI).

------------------------------------------------------------
## ğŸ—ï¸ Arquitectura del Sistema

- **PatrÃ³n arquitectÃ³nico utilizado:**  
  La aplicaciÃ³n adopta una arquitectura modular monolÃ­tica â€œhÃ­bridaâ€ en la que se separa la lÃ³gica de presentaciÃ³n (Frontend) de la lÃ³gica de negocio (Backend).  
  - La **Capa de PresentaciÃ³n** se implementa con Streamlit. Esta capa se encarga de la carga de archivos, el manejo de la interacciÃ³n del usuario, la visualizaciÃ³n dinÃ¡mica de resultados y la gestiÃ³n del estado mediante `st.session_state`.  
  - La **Capa de LÃ³gica y AnÃ¡lisis** se compone de mÃ³dulos para:  
    â€¢ la extracciÃ³n y validaciÃ³n de archivos (utilizando PyPDF2 para documentos PDF),  
    â€¢ el procesamiento y parsing de conversaciones (incluyendo la anonimizaciÃ³n o redacciÃ³n de informaciÃ³n sensible, PII) y  
    â€¢ la integraciÃ³n con proveedores de Modelos de Lenguaje (LLM) mediante el mÃ³dulo LLMBackend.
  
- **Diagrama de componentes:**  

  ```mermaid
  graph LR
      A[Interfaz Streamlit (Frontend)] --> B[Procesamiento y ValidaciÃ³n de Archivos]
      A --> C[GestiÃ³n del Estado (st.session_state)]
      B --> D[ExtracciÃ³n de Texto (PyPDF2)]
      B --> E[Parser y RedacciÃ³n de PII]
      A --> F[LLMBackend (LÃ³gica de Negocio)]
      F --> G[Proveedores LLM (OpenAI, Anthropic, Gemini)]
  ```

- **Flujo de datos principal entre componentes:**  
  1. El usuario ingresa a la aplicaciÃ³n mediante la interfaz web y carga archivos (por ejemplo, PDFs o transcripciones).  
  2. Se valida el archivo (por ejemplo, comprobando su tamaÃ±o mediante `validate_file_size`) y se extrae el contenido textual utilizando la funciÃ³n `extract_text_from_pdf` (que utiliza PyPDF2).  
  3. El texto es enviado al mÃ³dulo de parser, donde se segmenta en turnos, se asignan metadatos (por ejemplo, conversation_id, timestamps, roles) y se redacta la PII.  
  4. El mÃ³dulo **LLMBackend** utiliza la configuraciÃ³n definida en la clase ModelConfig para enviar el contenido a los proveedores LLM (mediante prompts predefinidos) y obtener insights (anÃ¡lisis de sentimientos, detecciÃ³n de temas, recomendaciones, etc.).  
  5. Los resultados finales se almacenan en `st.session_state` y se presentan en la interfaz mediante paneles, grÃ¡ficos y tablas interactivas.

- **Dependencias crÃ­ticas y su propÃ³sito:**  
  - **Streamlit:** Facilita la creaciÃ³n de la interfaz web interactiva y la gestiÃ³n en tiempo real del estado de la sesiÃ³n.  
  - **PyPDF2:** Se utiliza para extraer el contenido textual de documentos PDF.  
  - **Pandas:** Permite manipular y visualizar datos (por ejemplo, para generar resÃºmenes y tableros).  
  - **LLM SDKs (openai, anthropic, google-genai):** Proveen la conexiÃ³n y la integraciÃ³n con proveedores externos de Modelos de Lenguaje para realizar anÃ¡lisis semÃ¡ntico avanzado.  
  - Otras librerÃ­as estÃ¡ndar (json, os, time, datetime, uuid, zipfile, io, typing) ofrecen funcionalidades bÃ¡sicas para manejo de datos, archivos y excepciones.

------------------------------------------------------------
## ğŸ“‹ Stack TecnolÃ³gico

- **Lenguajes:**  
  Principalmente Python (clasificado como â€œotherâ€ en el repositorio).

- **Frameworks / LibrerÃ­as:**  
  - **Streamlit:** (>= 1.49.1) para la creaciÃ³n de la interfaz web interactiva.  
  - **PyPDF2:** (>= 3.0.1) para la extracciÃ³n de texto de documentos PDF.  
  - **Pandas:** (>= 2.3.2) para el manejo y visualizaciÃ³n de datos en formato tabular.  
  - **LLM SDKs:**  
    - `openai` â€“ Para la integraciÃ³n con modelos de OpenAI.  
    - `anthropic` â€“ Para conectarse a proveedores de Anthropic.  
    - `google-genai` â€“ Para la integraciÃ³n con Google GenAI (Gemini u otros modelos).  
  - **LibrerÃ­as estÃ¡ndar:** json, os, time, datetime, uuid, zipfile, io, typing.

- **Base de Datos:**  
  No se utiliza una base de datos persistente; el almacenamiento se gestiona de manera transitoria en memoria a travÃ©s de `st.session_state`.

- **APIs externas:**  
  La aplicaciÃ³n se conecta a las APIs de proveedores de LLM (OpenAI, Anthropic y Google GenAI) para realizar anÃ¡lisis avanzados del contenido textual.

- **Infraestructura:**  
  La aplicaciÃ³n se despliega como una aplicaciÃ³n web simple con Streamlit, pudiendo ejecutarse en entornos locales, servidores o contenedores Docker para entornos de producciÃ³n.

------------------------------------------------------------
## ğŸ”§ Componentes Principales

### 1. AplicaciÃ³n Streamlit

- **PropÃ³sito:**  
  Gestionar la interfaz de usuario, la carga y validaciÃ³n de archivos, asÃ­ como la visualizaciÃ³n interactiva de resultados y el manejo del estado de la sesiÃ³n.  
- **UbicaciÃ³n:**  
  Generalmente en el archivo de entrada (por ejemplo, `app.py`, ubicado en la raÃ­z o en el directorio `app/`), junto a mÃ³dulos auxiliares como `parser.py` y `utils.py`.
- **Interfaces / Funcionalidades:**  
  - **ConfiguraciÃ³n de la PÃ¡gina:**  
    Uso de `st.set_page_config` para definir el tÃ­tulo, Ã­cono, layout y configuraciÃ³n del sidebar.
  - **GestiÃ³n del Estado:**  
    Uso de `st.session_state` para almacenar variables clave:
    - `analysis_results`
    - `run_id`
    - `uploaded_files_data`
    - `processing_complete`
  - **Funciones Auxiliares:**  
    - `extract_text_from_pdf(pdf_file) â†’ str`: Extrae el contenido textual del PDF usando PyPDF2 y gestiona posibles errores.  
    - `validate_file_size(file) â†’ bool`: Verifica que el tamaÃ±o del archivo no exceda el lÃ­mite preestablecido (por ejemplo, 100 MB).

- **Ejemplo de CÃ³digo:**

  ```python
  import streamlit as st
  import PyPDF2

  st.set_page_config(
      page_title="VoC Analyst - AnÃ¡lisis de Voz del Cliente con LLM",
      page_icon="ğŸ“Š",
      layout="wide",
      initial_sidebar_state="expanded"
  )

  if 'analysis_results' not in st.session_state:
      st.session_state.analysis_results = None
  if 'run_id' not in st.session_state:
      st.session_state.run_id = None
  if 'uploaded_files_data' not in st.session_state:
      st.session_state.uploaded_files_data = []
  if 'processing_complete' not in st.session_state:
      st.session_state.processing_complete = False

  def extract_text_from_pdf(pdf_file) -> str:
      """Extraer texto de archivo PDF"""
      try:
          pdf_reader = PyPDF2.PdfReader(pdf_file)
          text = ""
          for page in pdf_reader.pages:
              text += page.extract_text() + "\n"
          return text.strip()
      except Exception as e:
          st.error(f"Error al extraer texto de PDF: {str(e)}")
          return ""
  ```

---

### 2. MÃ³dulo LLMBackend

- **PropÃ³sito:**  
  Encapsular la lÃ³gica de integraciÃ³n con proveedores de modelos de lenguaje (LLM), permitiendo enviar el contenido textual a analizar y obtener insights como anÃ¡lisis de sentimientos, detecciÃ³n de temas y recomendaciones.  
- **UbicaciÃ³n:**  
  Se encuentra en el archivo `llm_backend.py` en la raÃ­z del proyecto.
- **Interfaces y Funcionalidades:**  
  - **ModelConfig:**  
    Clase de configuraciÃ³n que define:
    - `provider`: Nombre del proveedor (ej. "openai", "anthropic", "gemini").
    - `model`: Modelo a utilizar.
    - `api_key`: Clave de autenticaciÃ³n.
    - `max_retries` y `retry_delay`: ParÃ¡metros para gestionar reintentos.
    
    ```python
    from dataclasses import dataclass

    @dataclass
    class ModelConfig:
        provider: str  # 'openai', 'anthropic', 'gemini'
        model: str
        api_key: str
        max_retries: int = 3
        retry_delay: float = 1.0
    ```
  
  - **LLMBackend:**  
    MÃ©todos clave incluyen:
    - `__init__(config: ModelConfig)`: Inicializa el backend con la configuraciÃ³n proporcionada.
    - `_initialize_client()`: Selecciona e instancia el cliente del proveedor LLM segÃºn la configuraciÃ³n.
    - `_load_parse_prompt()` y `_load_analyze_prompt()`: Cargan los prompts necesarios para el anÃ¡lisis.
    - `analyze_text(text: str) â†’ Dict[str, Any]`: EnvÃ­a el texto junto con los prompts al proveedor LLM y retorna un diccionario con los insights generados.

- **Ejemplo Simplificado:**

  ```python
  class LLMBackend:
      def __init__(self, config: ModelConfig):
          self.config = config
          self.client = self._initialize_client()
          self.parse_prompt = self._load_parse_prompt()
          self.analyze_prompt = self._load_analyze_prompt()
      
      def _initialize_client(self):
          if self.config.provider == 'openai':
              return openai.OpenAI(api_key=self.config.api_key)
          elif self.config.provider == 'anthropic':
              return anthropic.Anthropic(api_key=self.config.api_key)
          elif self.config.provider == 'gemini':
              return genai.Client(api_key=self.config.api_key)
          else:
              raise ValueError(f"Proveedor no soportado: {self.config.provider}")
      
      def analyze_text(self, text: str) -> dict:
          response = self.client.create_completion(
              engine=self.config.model,
              prompt=f"{self.analyze_prompt}\n{text}",
              max_tokens=150
          )
          return {"analysis": response}
  ```

---

### 3. Parser y Procesamiento de Conversaciones

- **PropÃ³sito:**  
  Procesar y normalizar el contenido textual extraÃ­do o ingresado manualmente, estructurÃ¡ndolo en un formato JSON que incluya la informaciÃ³n de la conversaciÃ³n y que aplique redacciÃ³n de PII (anonimizaciÃ³n de datos sensibles).  
- **UbicaciÃ³n:**  
  Este mÃ³dulo se ubica en el archivo `parser.py` o en secciones dentro de `app.py`.
- **Funciones Clave:**  
  - Dividir el texto en turnos de conversaciÃ³n y asignar roles a los interlocutores.  
  - Extraer metadatos como `conversation_id`, timestamps y otros datos relevantes.  
  - Redactar PII utilizando expresiones regulares para reemplazar datos sensibles por etiquetas estÃ¡ndar (por ejemplo, [EMAIL], [PHONE], etc.).

---

## ğŸš€ APIs y Endpoints

**Nota:**  
Aunque la aplicaciÃ³n no expone endpoints REST pÃºblicos, se definen â€œAPIs internasâ€ a travÃ©s de funciones y mÃ©todos que orquestan el flujo de procesamiento:

- **FunciÃ³n: extract_text_from_pdf(pdf_file) â†’ str:**  
  Extrae el contenido textual de un archivo PDF usando PyPDF2, gestionando errores mediante bloques try/except y notificando con `st.error`.

- **FunciÃ³n: validate_file_size(file) â†’ bool:**  
  Verifica que el tamaÃ±o del archivo subido no exceda el lÃ­mite predefinido (ej. 100 MB).

- **MÃ©todo: LLMBackend.analyze_text(text: str) â†’ Dict[str, Any]:**  
  EnvÃ­a el texto (junto con un prompt predefinido) al proveedor LLM configurado y retorna un diccionario con los insights obtenidos (por ejemplo, anÃ¡lisis de sentimientos, detecciÃ³n de temas y recomendaciones).

- **Funciones del Parser:**  
  Transforman el contenido de la conversaciÃ³n en un objeto JSON estructurado, normalizando el texto y redactando informaciÃ³n sensible (PII).

---

## ğŸ’¾ Modelo de Datos

- **Entidades Principales: ConversaciÃ³n**
  - **Estructura JSON:**
    - `conversation_id`: Identificador Ãºnico (derivado del nombre del archivo o metadatos).
    - `messages`: Lista de mensajes, donde cada mensaje contiene:
      - `sender`: Rol del emisor (cliente, agente o desconocido).
      - `timestamp`: Momento de envÃ­o del mensaje (si se detecta).
      - `content`: Texto del mensaje con informaciÃ³n sensible ya redactada.
      - `metadata`: InformaciÃ³n adicional (por ejemplo, canal, duraciÃ³n, etc.).
    
- **Esquemas de Entrada y Salida:**
  - **Entrada:** Documentos PDF o textos que contengan la conversaciÃ³n.
  - **Salida:** Objeto JSON estructurado que contiene la conversaciÃ³n y, posteriormente, los insights generados por el anÃ¡lisis.
  
- **Validaciones y Transformaciones:**  
  Se valida que el contenido extraÃ­do no estÃ© vacÃ­o, se aplican reglas de redacciÃ³n para anonimizar PII y se estructura el resultado en un formato homogÃ©neo ideal para su visualizaciÃ³n y anÃ¡lisis.

---

## ğŸ› ï¸ GuÃ­a de Desarrollo

### ConfiguraciÃ³n del Entorno

1. **Prerrequisitos:**
   - Python 3.8 o superior.
   - ConexiÃ³n a internet para llamadas a APIs de proveedores LLM.
  
2. **InstalaciÃ³n:**
   - Clona el repositorio:
     ```bash
     git clone https://github.com/tu_usuario/VoC-Analyst.git
     cd VoC-Analyst
     ```
   - Crea y activa un entorno virtual:
     ```bash
     python -m venv venv
     source venv/bin/activate    # En Linux/Mac
     venv\Scripts\activate       # En Windows
     ```
   - Instala las dependencias:
     ```bash
     pip install -r requirements.txt
     ```

3. **Variables de Entorno:**
   Configura las API keys necesarias para los proveedores LLM mediante variables de entorno:
   - `OPENAI_API_KEY`
   - `ANTHROPIC_API_KEY`
   - `GEMINI_API_KEY`

---

### Estructura del CÃ³digo

El proyecto se organiza de la siguiente manera:

```
VoC-Analyst/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py                # Punto de entrada (Interfaz de usuario con Streamlit)
â”‚   â”œâ”€â”€ parser.py             # Funciones de parsing y normalizaciÃ³n de conversaciones
â”‚   â””â”€â”€ utils.py              # Funciones auxiliares (extracciÃ³n de texto, validaciÃ³n, etc.)
â”œâ”€â”€ llm_backend.py            # MÃ³dulo para integraciÃ³n con proveedores LLM
â”œâ”€â”€ requirements.txt          # Lista de dependencias
â””â”€â”€ README.md                 # DocumentaciÃ³n general y guÃ­a de usuario
```

- **Convenciones de Naming:**
  - Se emplean nombres descriptivos en minÃºsculas y separados por guiones bajos (por ejemplo, `extract_text_from_pdf`).

- **SeparaciÃ³n de LÃ³gica:**
  - Se mantiene la lÃ³gica de la interfaz (Streamlit) separada de la lÃ³gica de negocio (LLMBackend y Parser), utilizando inyecciÃ³n de dependencias mediante la clase `ModelConfig`.

- **Testing y ValidaciÃ³n:**
  - Se recomienda el uso de frameworks como `pytest` para pruebas unitarias en funciones crÃ­ticas como la extracciÃ³n de texto, la validaciÃ³n de archivos y la integraciÃ³n con el LLM.

- **Manejo de Errores y Logging:**
  - Utilizar bloques try/except para capturar y notificar errores.
  - Implementar un sistema de logging (opcional) para registrar eventos y facilitar la depuraciÃ³n.

---

## ğŸ” Puntos de AtenciÃ³n

- **Limitaciones Conocidas:**
  - La extracciÃ³n de texto depende de la calidad del PDF; documentos basados en imÃ¡genes pueden requerir OCR.
  - El anÃ¡lisis con modelos LLM es tan preciso como la claridad y formato del contenido extraÃ­do.
  - Actualmente, la aplicaciÃ³n procesa un archivo (o grupo de archivos) por sesiÃ³n; el procesamiento asÃ­ncrono o en lote podrÃ­a mejorar el rendimiento.

- **Consideraciones de Rendimiento:**
  - Archivos muy grandes (cerca o superiores a 100 MB) pueden afectar la velocidad de procesamiento.
  - Se recomienda implementar tÃ©cnicas de caching o procesamiento en lote para optimizar el rendimiento en anÃ¡lisis repetitivos.

- **Aspectos de Seguridad:**
  - Proteger las API keys utilizando variables de entorno y no exponerlas en el cÃ³digo fuente.
  - Redactar apropiadamente la informaciÃ³n sensible (PII) antes de enviarla a proveedores externos para cumplir con polÃ­ticas de privacidad.

- **Mejoras Sugeridas (TODOs):**
  - Ampliar el soporte a otros formatos de archivos (por ejemplo, TXT).
  - Integrar OCR para documentos PDF basados en imÃ¡genes.
  - Desarrollar procesamiento asÃ­ncrono y/o en lote para anÃ¡lisis masivos.
  - Mejorar la modularidad y el manejo de errores en el parser y en la comunicaciÃ³n con proveedores LLM.

---

## Diagrama del Sistema

El siguiente diagrama Mermaid resume la relaciÃ³n e interacciÃ³n entre los componentes principales:

```mermaid
graph LR
    A[Interfaz Streamlit] --> B[Procesamiento y ValidaciÃ³n de Archivos]
    B --> C[Parser y NormalizaciÃ³n de Conversaciones]
    A --> D[LLMBackend]
    D --> E[Proveedores LLM (OpenAI, Anthropic, Gemini)]
```

---

## ConclusiÃ³n

Esta documentaciÃ³n tÃ©cnica ofrece una visiÃ³n integral del sistema VoC Analyst, detallando su arquitectura, stack tecnolÃ³gico, componentes principales, APIs internas, modelo de datos y guÃ­a de desarrollo. Se recomienda mantener esta documentaciÃ³n actualizada a medida que se integren nuevas funcionalidades o se realicen cambios en la arquitectura.

Para cualquier duda, sugerencia o contribuciÃ³n, consulta el repositorio de issues o contacta al equipo de desarrollo.

------------------------------------------------------------
## Diagrama Final

```mermaid
graph LR
App[app] --> Deps[dependencies]
```

------------------------------------------------------------
Happy Coding y Â¡Ã©xito en el anÃ¡lisis de la Voz del Cliente!

Para cualquier consulta adicional, por favor revisa el repositorio de issues o contacta directamente al equipo de soporte.

------------------------------------------------------------
## Diagrama (Resumen Visual)

```mermaid
graph LR
App["app"] --> Deps["dependencies"]
```

------------------------------------------------------------


## Diagrama
```mermaid
graph LR\nApp["app"]-->Deps["dependencies"]\n
```
