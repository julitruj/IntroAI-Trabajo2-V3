# Documentaci√≥n del Proyecto

## Documentaci√≥n T√©cnica

A continuaci√≥n se presenta la documentaci√≥n t√©cnica completa en Markdown para desarrolladores del repositorio VoC Analyst. La documentaci√≥n abarca la arquitectura general, los componentes principales, APIs internas y gu√≠as de desarrollo, con el objetivo de facilitar la comprensi√≥n, extensi√≥n e integraci√≥n del sistema.

---

# VoC Analyst ‚Äì Documentaci√≥n T√©cnica

VoC Analyst es una aplicaci√≥n orientada al an√°lisis de la Voz del Cliente (VoC). Utiliza procesamiento de archivos (por ejemplo, PDF), extracci√≥n de texto, an√°lisis de conversaciones y generaci√≥n de insights mediante Modelos de Lenguaje (LLM). La interfaz de usuario se implementa con Streamlit, mientras que el backend integra m√∫ltiples proveedores LLM (como OpenAI, Anthropic y Google GenAI) para proveer an√°lisis avanzados.

---

## Tabla de Contenidos

1. [Resumen del Repositorio](#resumen-del-repositorio)
2. [Arquitectura General](#arquitectura-general)
3. [Componentes Principales](#componentes-principales)  
   3.1 [Aplicaci√≥n Streamlit](#aplicaci√≥n-streamlit)  
   3.2 [M√≥dulo LLMBackend](#m√≥dulo-llmbackend)  
   3.3 [Procesamiento y Extracci√≥n de Archivos](#procesamiento-y-extracci√≥n-de-archivos)  
   3.4 [An√°lisis y Parseo de Conversaciones](#an√°lisis-y-parseo-de-conversaciones)
4. [APIs Internas y Funciones Destacadas](#apis-internas-y-funciones-destacadas)
5. [Configuraci√≥n y Dependencias](#configuraci√≥n-y-dependencias)
6. [Gu√≠as de Desarrollo](#gu√≠as-de-desarrollo)  
   6.1 [Instalaci√≥n y Ejecuci√≥n](#instalaci√≥n-y-ejecuci√≥n)  
   6.2 [Extensi√≥n y Configuraci√≥n del LLMBackend](#extensi√≥n-y-configuraci√≥n-del-llmbackend)  
   6.3 [Pruebas y Validaci√≥n](#pruebas-y-validaci√≥n)
7. [Diagrama de Arquitectura](#diagrama-de-arquitectura)

---

## Resumen del Repositorio

- **Lenguajes:**  
  - Se han identificado archivos clasificados como _other_ (aproximadamente 16 archivos), lo que indica la utilizaci√≥n de scripts y archivos de configuraci√≥n.
  
- **Endpoints:**  
  - No se detectaron endpoints REST expl√≠citos; la comunicaci√≥n se lleva a cabo dentro del flujo de la aplicaci√≥n web y el backend LLM.

- **Resumen de funcionalidades:**  
  - Procesamiento interactivo de archivos (por ejemplo, PDFs) mediante extracci√≥n de texto.  
  - Uso de modelos de lenguaje (LLM) para an√°lisis y parseo de conversaciones.  
  - Interfaz de usuario implementada con Streamlit para visualizaci√≥n de resultados y configuraci√≥n de an√°lisis.

---

## Arquitectura General

La arquitectura de VoC Analyst se estructura en dos grandes bloques:

1. **Interfaz de Usuario (Frontend):**
   - Implementada completamente en Streamlit.
   - Se encarga de la carga de archivos, presentaci√≥n de resultados y gesti√≥n del estado de la sesi√≥n.

2. **Backend para An√°lisis LLM:**
   - Integraci√≥n con diversos proveedores de LLM a trav√©s del m√≥dulo LLMBackend.
   - Encapsula la l√≥gica de an√°lisis, comunicaci√≥n con APIs externas y procesamiento de resultados.
  
La siguiente representaci√≥n en Mermaid resume la relaci√≥n principal entre la aplicaci√≥n y sus dependencias:

```mermaid
graph LR
  App[app] --> Deps[dependencies]
```

---

## Componentes Principales

### Aplicaci√≥n Streamlit

- **Descripci√≥n:**  
  La interfaz construida con Streamlit facilita la interacci√≥n del usuario, permitiendo:
  - Configuraci√≥n de la p√°gina (t√≠tulo, icono, layout, barra lateral).
  - Carga y almacenamiento temporal de archivos y resultados mediante el estado de sesi√≥n.
  - Invocaci√≥n de funciones para extraer textos (por ejemplo, de PDFs) y validar archivos.
  
- **C√≥digo Representativo:**

  ```python
  import streamlit as st
  import json
  import pandas as pd
  import time
  from datetime import datetime
  import uuid
  import zipfile
  import io
  import os
  from typing import List, Dict, Any, Optional
  import PyPDF2
  from llm_backend import LLMBackend, ModelConfig

  st.set_page_config(
      page_title="VoC Analyst - An√°lisis de Voz del Cliente con LLM",
      page_icon="üìä",
      layout="wide",
      initial_sidebar_state="expanded"
  )

  if 'analysis_results' not in st.session_state:
      st.session_state.analysis_results = None
  if 'run_id' not in st.session_state:
      st.session_state.run_id = None
  if 'uploaded_files_data' not in st.session_state:
      st.session_state.uploaded_files_data = []
  if 'processing_complete' not in st.session_state:
      st.session_state.processing_complete = False

  def extract_text_from_pdf(pdf_file) -> str:
      """Extraer texto de archivo PDF"""
      try:
          pdf_reader = PyPDF2.PdfReader(pdf_file)
          text = ""
          for page in pdf_reader.pages:
              text += page.extract_text() + "\n"
          return text.strip()
      except Exception as e:
          st.error(f"Error al extraer texto de PDF: {str(e)}")
          return ""
  ```

### M√≥dulo LLMBackend

- **Descripci√≥n:**  
  Encapsula y abstrae la comunicaci√≥n con distintos proveedores de modelos de lenguaje. Permite configurar el proveedor, seleccionar modelo y gestionar reintentos en caso de fallos.
  
- **Componentes Clave:**
  - Clase `ModelConfig`: Define la configuraci√≥n necesaria para la selecci√≥n del modelo.
  - Clase `LLMBackend`: Inicializa el cliente LLM basado en la configuraci√≥n y carga prompts personalizados para parseo y an√°lisis.
  
- **C√≥digo Representativo:**

  ```python
  from dataclasses import dataclass
  import openai
  import anthropic
  from google import genai

  @dataclass
  class ModelConfig:
      """Configuration for LLM model selection"""
      provider: str  # 'openai', 'anthropic', 'gemini'
      model: str
      api_key: str
      max_retries: int = 3
      retry_delay: float = 1.0

  class LLMBackend:
      """Backend service for LLM-based VoC analysis"""
      
      def __init__(self, config: ModelConfig):
          self.config = config
          self.client = self._initialize_client()
          self.parse_prompt = self._load_parse_prompt()
          self.analyze_prompt = self._load_analyze_prompt()
      
      def _initialize_client(self):
          """Initialize the appropriate LLM client"""
          if self.config.provider == 'openai':
              return openai.OpenAI(api_key=self.config.api_key)
          elif self.config.provider == 'anthropic':
              return anthropic.Anthropic(api_key=self.config.api_key)
          elif self.config.provider == 'gemini':
              return genai.Client(api_key=self.config.api_key)
          else:
              raise ValueError(f"Unsupported provider: {self.config.provider}")
      
      def _load_parse_prompt(self) -> str:
          # Cargar o definir el prompt para la extracci√≥n de informaci√≥n de conversaciones
          return "Prompt de parseo de conversaci√≥n"
      
      def _load_analyze_prompt(self) -> str:
          # Cargar o definir el prompt para el an√°lisis de conversaciones y generaci√≥n de insights
          return "Prompt de an√°lisis de conversaci√≥n"
      
      def analyze_text(self, text: str) -> Dict[str, Any]:
          """Ejecuta el an√°lisis de VoC sobre el texto proporcionado"""
          # Ejemplo de proceso de an√°lisis con manejo de reintentos
          retries = 0
          while retries < self.config.max_retries:
              try:
                  # L√≥gica de invocaci√≥n al API de LLM con el prompt de an√°lisis
                  result = self.client.create_completion(
                      engine=self.config.model,
                      prompt=(self.analyze_prompt + "\n" + text),
                      max_tokens=150
                  )
                  return result
              except Exception as e:
                  retries += 1
                  time.sleep(self.config.retry_delay)
                  logger.error(f"Error al analizar texto: {e}. Reintento {retries}")
          raise RuntimeError("Se super√≥ el n√∫mero m√°ximo de reintentos para analizar el texto.")
  ```

### Procesamiento y Extracci√≥n de Archivos

- **Descripci√≥n:**  
  M√≥dulo encargado de la carga y procesamiento de archivos. Se enfoca en extraer texto desde archivos PDF y validar el tama√±o de los archivos.
  
- **Funciones Clave:**
  - `extract_text_from_pdf(pdf_file)`: Extrae y concatena el texto de cada p√°gina de un documento PDF.
  - `validate_file_size(file)`: Revisa que el tama√±o del archivo no exceda el l√≠mite especificado (por ejemplo, 100 MB).

### An√°lisis y Parseo de Conversaciones

- **Descripci√≥n:**  
  Implementa la l√≥gica para transformar y analizar conversaciones extra√≠das de archivos o entradas de usuario, permitiendo:
  - La normalizaci√≥n del texto.
  - La segmentaci√≥n por temas.
  - La identificaci√≥n de sentimientos y emociones.
  
- **Notas:**  
  La integraci√≥n con LLMBackend es clave para trasladar la conversaci√≥n procesada al modelo de lenguaje, el cual retorna insights y recomendaciones basadas en el an√°lisis.

---

## APIs Internas y Funciones Destacadas

A continuaci√≥n se listan las principales APIs y funciones que pueden ser de inter√©s para la extensi√≥n o integraci√≥n del proyecto:

- **LLMBackend.analyze_text(text: str) ‚Üí Dict[str, Any]:**  
  Procesa el texto ingresado utilizando el prompt de an√°lisis y retorna los resultados obtenidos del proveedor LLM.

- **extract_text_from_pdf(pdf_file) ‚Üí str:**  
  Funci√≥n auxiliar para extraer el contenido textual de un archivo PDF.  
  _Manejo de errores:_ Emite un mensaje de error mediante la interfaz Streamlit en caso de fallo en la extracci√≥n.

- **validate_file_size(file) ‚Üí bool:**  
  Valida que el tama√±o del archivo se encuentre dentro del rango permitido (por ejemplo, menor a 100 MB).

*Nota:* Otras funciones internas en el m√≥dulo de extracci√≥n y en la l√≥gica de Streamlit permiten gestionar el estado de la sesi√≥n (por ejemplo, almacenamiento de resultados, generaci√≥n de IDs √∫nicos para cada an√°lisis, etc.).

---

## Configuraci√≥n y Dependencias

- **Dependencias principales:**  
  - Python 3.x  
  - Streamlit  
  - Pandas  
  - PyPDF2  
  - openai  
  - anthropic  
  - google-genai (dependiente de la integraci√≥n con Google GenAI)

- **Instalaci√≥n de dependencias:**  
  Se recomienda utilizar un entorno virtual. Un ejemplo utilizando pip:

  ```bash
  python -m venv env
  source env/bin/activate  # En Windows: env\Scripts\activate
  pip install -r requirements.txt
  ```

- **Configuraci√≥n del proveedor LLM:**  
  Cada proveedor (OpenAI, Anthropic, Gemini) requiere una API key v√°lida. Configure la instancia de ModelConfig, por ejemplo:

  ```python
  from llm_backend import ModelConfig, LLMBackend

  config = ModelConfig(
      provider="openai",  # O 'anthropic' / 'gemini'
      model="text-davinci-003",
      api_key="TU_API_KEY_AQUI"
  )
  llm_service = LLMBackend(config)
  ```

---

## Gu√≠as de Desarrollo

### Instalaci√≥n y Ejecuci√≥n

1. Clona el repositorio:

   ```bash
   git clone https://github.com/tu_usuario/voc-analyst.git
   cd voc-analyst
   ```

2. Crea un entorno virtual e instala las dependencias:

   ```bash
   python -m venv env
   source env/bin/activate  # En Windows: env\Scripts\activate
   pip install -r requirements.txt
   ```

3. Ejecuta la aplicaci√≥n:

   ```bash
   streamlit run app.py
   ```

### Extensi√≥n y Configuraci√≥n del LLMBackend

- Para agregar soporte a nuevos proveedores de LLM, extienda la funci√≥n _initialize_client() en la clase LLMBackend.
- Aseg√∫rese de definir nuevos prompts para parseo o an√°lisis si es necesario.
- Pruebe siempre la conexi√≥n y respuesta del proveedor antes de despliegues en producci√≥n.

### Pruebas y Validaci√≥n

- Incluya pruebas unitarias para funciones cr√≠ticas, como:
  - Extracci√≥n de texto en archivos PDF.
  - Validaci√≥n de tama√±o y formato de archivos.
  - Resiliencia de la funci√≥n analyze_text() con manejo de reintentos.
- Utilice herramientas de testing (por ejemplo, pytest) y cubra casos de √©xito y escenarios de fallo.

---

## Diagrama de Arquitectura

El siguiente diagrama en Mermaid ilustra de forma simple la relaci√≥n entre la aplicaci√≥n principal y sus dependencias:

```mermaid
graph LR
    A[Interfaz Streamlit] --> B[LLMBackend]
    B --> C[Proveedor OpenAI]
    B --> D[Proveedor Anthropic]
    B --> E[Proveedor Gemini]
    A --> F[M√≥dulo Extracci√≥n de Archivos]
```

---

Con esta documentaci√≥n, los desarrolladores cuentan con una vista integral de la arquitectura y el funcionamiento interno de VoC Analyst. Se recomienda profundizar en cada m√≥dulo mediante la lectura de los comentarios y la experimentaci√≥n directa en el c√≥digo para facilitar futuras extensiones y mantenimientos.



## Diagrama
```mermaid
graph LR
App[app]-->Deps[dependencies]

```


---

## Gu√≠a de Usuario

# Gu√≠a del Usuario para la Herramienta de An√°lisis y Procesamiento de Informaci√≥n

Bienvenido a la aplicaci√≥n basada en Streamlit, dise√±ada para facilitar el an√°lisis y procesamiento de informaci√≥n a partir de archivos PDF utilizando modelos de lenguaje (IA). En esta gu√≠a, encontrar√°s una descripci√≥n de la aplicaci√≥n, las principales funcionalidades, instrucciones de uso y respuestas a las preguntas frecuentes.

---

## 1. Descripci√≥n de la Aplicaci√≥n

Esta herramienta combina una interfaz web interactiva creada con Streamlit, junto con potentes capacidades de procesamiento de archivos PDF y an√°lisis mediante modelos de lenguaje basados en inteligencia artificial. El objetivo principal es ayudar a los usuarios a extraer, analizar y comprender la informaci√≥n contenida en documentos PDF de forma r√°pida y sencilla.

**Caracter√≠sticas clave:**
- Interfaz web f√°cil de usar.
- Procesamiento autom√°tico de archivos PDF.
- An√°lisis inteligente de contenido utilizando modelos de lenguaje.
- Visualizaci√≥n interactiva de resultados.

---

## 2. Funcionalidades Principales

### 2.1 Interfaz Web Interactiva con Streamlit
- **Navegaci√≥n sencilla:** La aplicaci√≥n cuenta con una interfaz intuitiva dise√±ada con Streamlit, permitiendo a los usuarios cargar archivos, iniciar procesos de an√°lisis y visualizar resultados sin complicaciones.
- **Visualizaci√≥n din√°mica:** Resultados y gr√°ficos se actualizan en tiempo real conforme se realiza el procesamiento.

### 2.2 Procesamiento de Archivos PDF
- **Carga y extracci√≥n:** Permite al usuario subir documentos PDF. La herramienta extrae el texto y otras informaciones relevantes autom√°ticamente.
- **Manejo de documentos extensos:** Ideal para trabajar tanto con documentos breves como con reportes extensos.

### 2.3 An√°lisis con Modelos de Lenguaje (IA)
- **Comprensi√≥n sem√°ntica:** Utiliza modelos de lenguaje avanzados para analizar el contenido extra√≠do, identificando temas, patrones e informaci√≥n clave.
- **Generaci√≥n de res√∫menes:** Capacidad para ofrecer res√∫menes y respuestas a consultas espec√≠ficas basados en el contenido de los documentos.
- **Asistencia en toma de decisiones:** Ayuda a interpretar la informaci√≥n procesada, soportando la toma de decisiones basada en los datos contenidos en los archivos PDF.

---

## 3. C√≥mo Usar la Aplicaci√≥n

### Paso 1: Acceso a la Interfaz Web
1. Abra un navegador web y acceda a la URL designada para la aplicaci√≥n.
2. Espere a que la p√°gina cargue completamente. La interfaz principal de Streamlit se mostrar√°, presentando el men√∫ de opciones.

### Paso 2: Cargar Archivos PDF
1. En la secci√≥n de carga de documentos, haga clic en el bot√≥n "Seleccionar archivo" y elija el PDF que desea analizar.
2. Confirme la subida del archivo. La aplicaci√≥n comenzar√° a procesar el documento.

### Paso 3: Procesamiento y An√°lisis del documento
1. Una vez cargado el PDF, se realizar√° un procesamiento autom√°tico del texto.
2. La aplicaci√≥n emplear√° modelos de lenguaje para analizar el contenido y generar resultados relevantes.
3. Espere unos momentos mientras se completa el an√°lisis.

### Paso 4: Visualizaci√≥n y Exportaci√≥n de Resultados
1. Revise los resultados mostrados en pantalla: res√∫menes, gr√°ficos y puntos destacados del an√°lisis.
2. Opcionalmente, utilice las herramientas de filtrado y b√∫squeda para profundizar en √°reas espec√≠ficas del documento.
3. Si lo desea, exporte los resultados en formatos compatibles (por ejemplo, CSV, PDF o JSON).

---

## 4. Preguntas Frecuentes (FAQ)

### P: ¬øQu√© tipos de documentos puedo analizar?
R: Actualmente, la aplicaci√≥n est√° optimizada para archivos en formato PDF. Se est√°n explorando futuras incorporaciones para otros formatos.

### P: ¬øNecesito tener conocimientos t√©cnicos para usar la herramienta?
R: No, la interfaz est√° dise√±ada para ser sencilla e intuitiva. Con pasos claros y una navegaci√≥n asistida, cualquier usuario sin experiencia t√©cnica puede utilizar la aplicaci√≥n sin dificultad.

### P: ¬øCu√°nto tiempo tarda el an√°lisis de un documento?
R: La duraci√≥n del procesamiento depender√° del tama√±o y complejidad del PDF. Documentos m√°s extensos pueden tomar unos minutos, mientras que archivos peque√±os se procesan casi de inmediato.

### P: ¬øQu√© seguridad tiene mi informaci√≥n?
R: La aplicaci√≥n est√° desarrollada en Python y utiliza bibliotecas robustas de an√°lisis. Se han implementado medidas de seguridad para garantizar la privacidad de los documentos cargados, sin almacenar informaci√≥n sensible en servidores externos.

### P: ¬øC√≥mo puedo obtener soporte o reportar un problema?
R: Si encuentra alg√∫n inconveniente o necesita asistencia adicional, por favor p√≥ngase en contacto con el equipo de soporte a trav√©s del formulario de contacto disponible en la secci√≥n "Ayuda" o env√≠e un correo a soporte@nombredeaplicacion.com.

### P: ¬øExisten planes de agregar nuevas funcionalidades en el futuro?
R: S√≠, el equipo de desarrollo est√° trabajando continuamente en actualizaciones para incorporar nuevas caracter√≠sticas, mejorar el rendimiento y ampliar la compatibilidad con otros formatos y an√°lisis.

---

## 5. Conclusi√≥n

Esta herramienta es una soluci√≥n integral para transformar, analizar y visualizar informaci√≥n contenida en documentos PDF con la ayuda de la inteligencia artificial. Esperamos que esta gu√≠a le permita aprovechar al m√°ximo la aplicaci√≥n. ¬°Comience a explorar y optimice su proceso de an√°lisis de informaci√≥n hoy mismo!

Si tiene m√°s preguntas o necesita asistencia adicional, no dude en contactar al equipo de soporte.

--- 

¬°Gracias por utilizar nuestra aplicaci√≥n!